Index: federated_learning_keras_consensus_FL_MNIST_I.py
===================================================================
diff --git a/federated_learning_keras_consensus_FL_MNIST_I.py b/federated_learning_keras_consensus_FL_MNIST_I.py
deleted file mode 100644
--- a/federated_learning_keras_consensus_FL_MNIST_I.py	(revision 48a4a0ba4acc8c257c486dff115b9a6b42644164)
+++ /dev/null	(revision 48a4a0ba4acc8c257c486dff115b9a6b42644164)
@@ -1,684 +0,0 @@
-from DataSets import MnistData
-from consensus.consensus_v3 import CFA_process
-from consensus.parameter_server_v2 import Parameter_Server
-# use only for consensus , PS only for energy efficiency
-# from ReplayMemory import ReplayMemory
-import numpy as np
-import os
-import tensorflow as tf
-from tensorflow import keras
-from tensorflow.keras import layers
-from tensorflow.keras import models
-import argparse
-import warnings
-import glob
-import datetime
-import scipy.io as sio
-import multiprocessing
-import math
-from matplotlib.pyplot import pause
-import time
-
-
-
-warnings.filterwarnings("ignore")
-parser = argparse.ArgumentParser()
-parser.add_argument('-resume', default=0, help="set 1 to resume from a previous simulation, 0 to start from the beginning", type=float)
-parser.add_argument('-PS', default=0, help="set 1 to enable PS server and FedAvg, set 0 to disable PS", type=float)
-parser.add_argument('-consensus', default=0, help="set 1 to enable consensus, set 0 to disable", type=float)
-parser.add_argument('-mu', default=0.001, help="sets the learning rate for all setups", type=float)
-parser.add_argument('-eps', default=1, help="sets the mixing parameters for model averaging (CFA)", type=float)
-parser.add_argument('-target', default=0.05, help="sets the target loss to stop federation", type=float)
-parser.add_argument('-K', default=100, help="sets the number of network devices", type=int)
-parser.add_argument('-Ka', default=20, help="sets the number of active devices per round in FA (<= K)", type=int)
-parser.add_argument('-N', default=1, help="sets the max. number of neighbors per device per round in CFA", type=int)
-parser.add_argument('-Ka_consensus', default=30, help="sets the number of active devices for consensus", type=int)
-parser.add_argument('-samp', default=500, help="sets the number samples per device", type=int)
-parser.add_argument('-noniid_assignment', default=0, help=" set 0 for iid assignment, 1 for non-iid random", type=int)
-parser.add_argument('-run', default=0, help=" set the run id", type=int)
-parser.add_argument('-random_data_distribution', default=0, help=" set 0 for fixed distribution, 1 for time-varying", type=int)
-parser.add_argument('-batches', default=5, help="sets the number of batches per learning round", type=int)
-parser.add_argument('-batch_size', default=100, help="sets the batch size per learning round", type=int)
-parser.add_argument('-graph', default=6, help="sets the input graph: 0 for default graph, >0 uses the input graph in vGraph.mat, and choose one graph from the available adjacency matrices", type=int)
-parser.add_argument('-modelselection', default=0, help="sets the model: 0 for lenet-1", type=int)
-args = parser.parse_args()
-
-devices = args.K  # NUMBER OF DEVICES
-active_devices_per_round = args.Ka
-max_epochs = 200
-condition = args.modelselection
-
-
-if args.consensus == 1:
-    federated = True
-    parameter_server = False
-elif args.PS == 1:
-    federated = False
-    parameter_server = True
-else: # CL: CENTRALIZED LEARNING ON DEVICE 0 (DATA CENTER)
-    federated = False
-    parameter_server = False
-
-
-
-################# consensus, create the scheduling function ################
-scheduling_tx = np.zeros((devices, max_epochs*2), dtype=int)
-if parameter_server and not federated:
-    indexes_tx = np.zeros((args.Ka, max_epochs*2), dtype=int)
-    for k in range(max_epochs*2):
-        # inds = np.random.choice(devices, args.Ka, replace=False)
-        sr = devices - args.Ka + 1
-        sr2 = k % sr
-        inds = np.arange(sr2, args.Ka + sr2)
-        scheduling_tx[inds, k] = 1
-        indexes_tx[:,k] = inds
-elif not parameter_server and federated:
-    indexes_tx = np.zeros((args.Ka_consensus, max_epochs*2), dtype=int)
-    for k in range(max_epochs*2):
-        # inds = np.random.choice(devices, args.Ka_consensus, replace=False)
-        sr = devices - args.Ka_consensus + 1
-        sr2 = k % sr
-        inds = np.arange(sr2, args.Ka_consensus + sr2)
-        scheduling_tx[inds, k] = 1
-        indexes_tx[:, k] = inds
-###########################################################################
-
-if active_devices_per_round > devices:
-    active_devices_per_round = devices
-
-target_loss = args.target
-# Configuration paramaters for the whole setup
-seed = 42
-
-# batch_size = 5  # Size of batch taken from replay buffer
-batch_size = args.batch_size
-number_of_batches = args.batches
-training_set_per_device = args.samp # NUMBER OF TRAINING SAMPLES PER DEVICE
-validation_train = 60000  # VALIDATION and training DATASET size
-validation_test = 10000
-
-if (training_set_per_device > validation_train/args.K):
-    training_set_per_device = math.floor(validation_train/args.K)
-    print(training_set_per_device)
-
-if batch_size > training_set_per_device:
-    batch_size = training_set_per_device
-
-# if batch_size*number_of_batches > training_set_per_device:
-#     number_of_batches = math.floor(training_set_per_device/batch_size)
-
-# number_of_batches = int(training_set_per_device/batch_size)
-# number_of_batches = args.batches
-
-number_of_batches_for_validation = int(validation_test/batch_size)
-
-print("Number of batches for learning {}".format(number_of_batches))
-
-max_lag = 1 # consensus max delay 2= 2 epochs max
-refresh_server = 1 # refresh server updates (in sec)
-
-n_outputs = 10  # 6 classes
-
-validation_start = 1 # start validation in epochs
-
-# Using huber loss for stability
-loss_function = keras.losses.Huber()
-
-# save scheduling format
-# dict_0 = {"scheduling": scheduling_tx, "devices_scheduling": indexes_tx}
-# sio.savemat("results/matlab/CFA_scheduling_devices_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}.mat".format(devices, args.N, number_of_batches, batch_size, args.noniid_assignment, args.run), dict_0)
-
-
-def get_noniid_data(total_training_size, devices, batch_size):
-    samples = np.random.random_integers(batch_size, total_training_size - batch_size * (devices - 1),
-                                        devices)  # create random numbers
-    samples = samples / np.sum(samples, axis=0) * total_training_size  # force them to sum to totals
-    # Ignore the following if you don't need integers
-    samples = np.round(samples)  # transform them into integers
-    remainings = total_training_size - np.sum(samples, axis=0)  # check if there are corrections to be done
-    step = 1 if remainings > 0 else -1
-    while remainings != 0:
-        i = np.random.randint(devices)
-        if samples[i] + step >= 0:
-            samples[i] += step
-            remainings -= step
-    return samples
-####
-
-def preprocess_observation(obs, batch_size):
-    img = obs# crop and downsize
-    img = (img).astype(np.float)
-    return img.reshape(batch_size, 28, 28, 1)
-
-def create_q_model():
-    # Network defined by the Deepmind paper
-    inputs = layers.Input(shape=(28, 28, 1,))
-
-    if condition == 0:
-        # lenet - 1
-     layer1 = layers.Conv2D(4, kernel_size=(5, 5), activation="relu")(inputs)
-     layer2 = layers.AveragePooling2D(pool_size=(2, 2))(layer1)
-     layer3 = layers.Conv2D(8, kernel_size=(5, 5), activation="relu")(layer2)
-     layer4 = layers.AveragePooling2D(pool_size=(2, 2))(layer3)
-     layer5 = layers.Flatten()(layer4)
-
-    elif condition == 1:
-        layer1 = layers.Conv2D(32, kernel_size=(3, 3), activation="relu")(inputs)
-        layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)
-        layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(layer2)
-        layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)
-        layer5 = layers.Flatten()(layer4)
-
-    else:
-        layer1 = layers.Conv2D(14, kernel_size=(3, 3), activation="relu")(inputs)
-        layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)
-        layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(layer2)
-        layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)
-        layer5 = layers.Flatten()(layer4)
-
-    # Convolutions
-    # layer1 = layers.Conv2D(32, 8, strides=4, activation="relu")(inputs)
-    # layer2 = layers.Conv2D(64, 4, strides=2, activation="relu")(layer1)
-    # layer3 = layers.Conv2D(64, 3, strides=1, activation="relu")(layer2)
-    #
-    # layer4 = layers.Flatten()(layer3)
-    #
-    # layer5 = layers.Dense(512, activation="relu")(layer4)
-    classification = layers.Dense(n_outputs, activation="linear")(layer5)
-
-    return keras.Model(inputs=inputs, outputs=classification)
-
-def processParameterServer(devices, active_devices_per_round, federated, refresh_server=1):
-    model_global = create_q_model()
-    model_parameters_initial = np.asarray(model_global.get_weights())
-    parameter_server = Parameter_Server(devices, model_parameters_initial, active_devices_per_round, indexes_tx)
-    global_target_model = 'results/model_global.npy'
-    global_epoch = 'results/epoch_global.npy'
-    epoch_count = 0
-    np.save(global_target_model, model_parameters_initial)
-    np.save(global_epoch, epoch_count)
-    pause(2) # wait for neighbors
-    while True:
-        pause(refresh_server) # refresh global model on every xx seconds
-        fileList = glob.glob('*.mat', recursive=False)
-        if len(fileList) == devices:
-            # stop the server
-            break
-        else:
-            np.save(global_target_model, parameter_server.federated_target_weights_aggregation(epoch_count, aggregation_type=0))
-            epoch_count += 1
-            np.save(global_epoch, epoch_count)
-
-
-# execute for each deployed device
-def processData(device_index, start_samples, samples, federated, full_data_size, number_of_batches, parameter_server, sample_distribution):
-    pause(5) # PS server (if any) starts first
-    checkpointpath1 = 'results/model{}.h5'.format(device_index)
-    outfile = 'results/dump_train_variables{}.npz'.format(device_index)
-    outfile_models = 'results/dump_train_model{}.npy'.format(device_index)
-    global_model = 'results/model_global.npy'
-    global_epoch = 'results/epoch_global.npy'
-
-    np.random.seed(1)
-    tf.random.set_seed(1)  # common initialization
-
-    learning_rate = args.mu
-    learning_rate_local = learning_rate
-
-    B = np.ones((devices, devices)) - tf.one_hot(np.arange(devices), devices)
-    Probabilities = B[device_index, :]/(devices - 1)
-    training_signal = False
-
-    # check for backup variables on start
-    if os.path.isfile(checkpointpath1):
-        train_start = False
-
-        # backup the model and the model target
-        model = models.load_model(checkpointpath1)
-        data_history = []
-        label_history = []
-        local_model_parameters = np.load(outfile_models, allow_pickle=True)
-        model.set_weights(local_model_parameters.tolist())
-
-        dump_vars = np.load(outfile, allow_pickle=True)
-        frame_count = dump_vars['frame_count']
-        epoch_loss_history = dump_vars['epoch_loss_history'].tolist()
-        running_loss = np.mean(epoch_loss_history[-5:])
-        epoch_count = dump_vars['epoch_count']
-    else:
-        train_start = True
-        model = create_q_model()
-        data_history = []
-        label_history = []
-        frame_count = 0
-        # Experience replay buffers
-        epoch_loss_history = []
-        epoch_count = 0
-        running_loss = math.inf
-
-    if parameter_server:
-        epoch_global = 0
-
-    training_end = False
-
-    a = model.get_weights()
-    # set an arbitrary optimizer, here Adam is used
-    optimizer = keras.optimizers.Adam(learning_rate=args.mu, clipnorm=1.0)
-    # create a data object (here radar data)
-    # start = time.time()
-    data_handle = MnistData(device_index, start_samples, samples, full_data_size, args.random_data_distribution)
-    # end = time.time()
-    # time_count = (end - start)
-    # print(Training time"time_count)
-    # create a consensus object
-    cfa_consensus = CFA_process(devices, device_index, args.N)
-
-    while True:  # Run until solved
-        # collect 1 batch
-        frame_count += 1
-        obs, labels = data_handle.getTrainingData(batch_size)
-        data_batch = preprocess_observation(obs, batch_size)
-
-        # Save data and labels in the current learning session
-        data_history.append(data_batch)
-        label_history.append(labels)
-
-
-        if frame_count % number_of_batches == 0:
-            if not parameter_server:
-                epoch_count += 1
-            # check scheduling for federated
-            if federated:
-                if epoch_count == 1 or scheduling_tx[device_index, epoch_count] == 1:
-                    training_signal = False
-                else:
-                    # stop all computing, just save the previous model
-                    training_signal = True
-                    model_weights = np.asarray(model.get_weights())
-                    model.save(checkpointpath1, include_optimizer=True, save_format='h5')
-                    np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,
-                         training_end=training_end, epoch_count=epoch_count, loss=running_loss)
-                    np.save(outfile_models, model_weights)
-            # check scheduling for parameter server
-            if parameter_server:
-                while not os.path.isfile(global_epoch):
-                    # implementing consensus
-                    print("waiting")
-                    pause(1)
-                try:
-                    epoch_global = np.load(global_epoch, allow_pickle=True)
-                except:
-                    pause(5)
-                    print("retrying opening global epoch counter")
-                    try:
-                        epoch_global = np.load(global_epoch, allow_pickle=True)
-                    except:
-                        print("failed reading global epoch")
-
-                if epoch_global == 0:
-                    training_signal = False
-
-                elif scheduling_tx[device_index, epoch_global] == 1:
-                    if epoch_global > epoch_count:
-                        epoch_count = epoch_global
-                        training_signal = False
-                    else:
-                        training_signal = True
-                else:
-                    # stop all computing, just save the previous model
-                    training_signal = True
-
-                # always refresh the local model using the PS one
-                stop_aggregation = False
-                while not os.path.isfile(global_model):
-                    # implementing consensus
-                    print("waiting")
-                    pause(1)
-                try:
-                    model_global = np.load(global_model, allow_pickle=True)
-                except:
-                    pause(5)
-                    print("retrying opening global model")
-                    try:
-                        model_global = np.load(global_model, allow_pickle=True)
-                    except:
-                        print("halting aggregation")
-                        stop_aggregation = True
-
-                if not stop_aggregation:
-                    model.set_weights(model_global.tolist())
-
-                if training_signal:
-                    model_weights = np.asarray(model.get_weights())
-                    model.save(checkpointpath1, include_optimizer=True, save_format='h5')
-                    np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,
-                             training_end=training_end, epoch_count=epoch_count, loss=running_loss)
-                    np.save(outfile_models, model_weights)
-            # check schedulting for parameter server
-
-        # Local learning update every "number of batches" batches
-        time_count = 0
-        if frame_count % number_of_batches == 0 and not training_signal:
-            # run local batches
-            for i in range(number_of_batches):
-                start = time.time()
-                data_sample = np.array(data_history[i])
-                label_sample = np.array(label_history[i])
-
-                # Create a mask to calculate loss
-                masks = tf.one_hot(label_sample, n_outputs)
-
-                with tf.GradientTape() as tape:
-                    # Train the model on data samples
-                    classes = model(data_sample)
-                    # Apply the masks
-                    class_v = tf.reduce_sum(tf.multiply(classes, masks), axis=1)
-                    # Calculate loss
-                    loss = loss_function(label_sample, class_v)
-
-                # Backpropagation
-                grads = tape.gradient(loss, model.trainable_variables)
-                optimizer.apply_gradients(zip(grads, model.trainable_variables))
-                end = time.time()
-                time_count = time_count + (end-start)/number_of_batches
-            if not parameter_server and not federated:
-                print('Average batch training time {:.2f}'.format(time_count))
-            del data_history
-            del label_history
-            data_history = []
-            label_history = []
-
-            model_weights = np.asarray(model.get_weights())
-            model.save(checkpointpath1, include_optimizer=True, save_format='h5')
-            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,
-                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)
-            np.save(outfile_models, model_weights)
-
-
-            #  Consensus round
-            # update local model
-            cfa_consensus.update_local_model(model_weights)
-            # neighbor = cfa_consensus.get_connectivity(device_index, args.N, devices) # fixed neighbor
-
-            if not train_start:
-                if federated and not training_signal:
-                    eps_c = 1 / (args.N + 1)
-                    # apply consensus for model parameter
-                    # neighbor = np.random.choice(np.arange(devices), args.N, p=Probabilities, replace=False) # choose neighbor
-                    neighbor = np.random.choice(indexes_tx[:, epoch_count - 1], args.N, replace=False) # choose neighbor
-                    while neighbor == device_index:
-                        neighbor = np.random.choice(indexes_tx[:, epoch_count - 1], args.N,
-                                                    replace=False)  # choose neighbor
-                    print("Consensus from neighbor {} for device {}, local loss {:.2f}".format(neighbor, device_index,
-                                                                                               loss.numpy()))
-
-                    model.set_weights(cfa_consensus.federated_weights_computing(neighbor, args.N, epoch_count, eps_c, max_lag))
-                    if cfa_consensus.getTrainingStatusFromNeightbor():
-                        # a neighbor completed the training, with loss < target, transfer learning is thus applied (the device will copy and reuse the same model)
-                        training_signal = True # stop local learning, just do validation
-            else:
-                print("Warm up")
-                train_start = False
-
-            # check if parameter server is enabled
-            # stop_aggregation = False
-
-            # if parameter_server:
-            #     # pause(refresh_server)
-            #     while not os.path.isfile(global_model):
-            #         # implementing consensus
-            #         print("waiting")
-            #         pause(1)
-            #     try:
-            #         model_global = np.load(global_model, allow_pickle=True)
-            #     except:
-            #         pause(5)
-            #         print("retrying opening global model")
-            #         try:
-            #             model_global = np.load(global_model, allow_pickle=True)
-            #         except:
-            #             print("halting aggregation")
-            #             stop_aggregation = True
-            #
-            #     if not stop_aggregation:
-            #         # print("updating from global model inside the parmeter server")
-            #         for k in range(cfa_consensus.layers):
-            #             # model_weights[k] = model_weights[k]+ 0.5*(model_global[k]-model_weights[k])
-            #             model_weights[k] = model_global[k]
-            #         model.set_weights(model_weights.tolist())
-            #
-            #     while not os.path.isfile(global_epoch):
-            #         # implementing consensus
-            #         print("waiting")
-            #         pause(1)
-            #     try:
-            #         epoch_global = np.load(global_epoch, allow_pickle=True)
-            #     except:
-            #         pause(5)
-            #         print("retrying opening global epoch counter")
-            #         try:
-            #             epoch_global = np.load(global_epoch, allow_pickle=True)
-            #         except:
-            #             print("halting aggregation")
-
-            del model_weights
-
-
-        #start = time.time()
-        # validation tool for device 'device_index'
-        if epoch_count > validation_start and frame_count % number_of_batches == 0:
-            avg_cost = 0.
-            for i in range(number_of_batches_for_validation):
-                obs_valid, labels_valid = data_handle.getTestData(batch_size, i)
-                # obs_valid, labels_valid = data_handle.getRandomTestData(batch_size)
-                data_valid = preprocess_observation(np.squeeze(obs_valid), batch_size)
-                data_sample = np.array(data_valid)
-                label_sample = np.array(labels_valid)
-                # Create a mask to calculate loss
-                masks = tf.one_hot(label_sample, n_outputs)
-                classes = model(data_sample)
-                # Apply the masks
-                class_v = tf.reduce_sum(tf.multiply(classes, masks), axis=1)
-                # Calculate loss
-                loss = loss_function(label_sample, class_v)
-                avg_cost += loss / number_of_batches_for_validation  # Training loss
-            epoch_loss_history.append(avg_cost)
-            print("Device {} epoch count {}, validation loss {:.2f}".format(device_index, epoch_count,
-                                                                                 avg_cost))
-            # mean loss for last 5 epochs
-            running_loss = np.mean(epoch_loss_history[-1:])
-        #end = time.time()
-        #time_count = (end - start)
-        #print(time_count)
-
-        if running_loss < target_loss:  # Condition to consider the task solved
-            print("Solved for device {} at epoch {} with average loss {:.2f} !".format(device_index, epoch_count, running_loss))
-            training_end = True
-            model_weights = np.asarray(model.get_weights())
-            model.save(checkpointpath1, include_optimizer=True, save_format='h5')
-            # model_target.save(checkpointpath2, include_optimizer=True, save_format='h5')
-            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,
-                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)
-            np.save(outfile_models, model_weights)
-
-            if federated:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                      "parameter_server": parameter_server, "devices": devices, "neighbors": args.N,
-                      "active_devices": args.Ka_consensus,
-                      "batches": number_of_batches, "batch_size": batch_size, "samples": samples, "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-            elif parameter_server:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                          "parameter_server": parameter_server, "devices": devices,
-                          "active_devices": active_devices_per_round,
-                          "batches": number_of_batches, "batch_size": batch_size, "samples": samples,
-                          "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-            else:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                          "parameter_server": parameter_server, "devices": devices,
-                          "batches": number_of_batches, "batch_size": batch_size, "samples": samples,
-                          "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-
-            if federated:
-                sio.savemat(
-                    "results/matlab/CFA_device_{}_samples_{}_devices_{}_active_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(
-                        device_index, samples, devices, args.Ka_consensus, args.N, number_of_batches, batch_size, args.noniid_assignment, args.run, args.random_data_distribution), dict_1)
-                sio.savemat(
-                    "CFA_device_{}_samples_{}_devices_{}_neighbors_{}_batches_{}_size{}.mat".format(
-                        device_index, samples, devices, args.N, number_of_batches, batch_size), dict_1)
-            elif parameter_server:
-                sio.savemat(
-                    "results/matlab/FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(
-                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size, args.noniid_assignment,args.run, args.random_data_distribution), dict_1)
-                sio.savemat(
-                    "FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}.mat".format(
-                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size), dict_1)
-            else: # CL
-                sio.savemat(
-                    "results/matlab/CL_samples_{}_devices_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(samples, devices, number_of_batches, batch_size,
-                                                                                                                         args.noniid_assignment, args.run, args.random_data_distribution), dict_1)
-            break
-
-        if epoch_count > max_epochs:  # stop simulation
-            print("Unsolved for device {} at epoch {}!".format(device_index, epoch_count))
-            training_end = True
-            model_weights = np.asarray(model.get_weights())
-            model.save(checkpointpath1, include_optimizer=True, save_format='h5')
-            # model_target.save(checkpointpath2, include_optimizer=True, save_format='h5')
-            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,
-                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)
-            np.save(outfile_models, model_weights)
-
-            if federated:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                          "parameter_server": parameter_server, "devices": devices, "neighbors": args.N,
-                          "active_devices": args.Ka_consensus,
-                          "batches": number_of_batches, "batch_size": batch_size, "samples": samples,
-                          "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-            elif parameter_server:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                          "parameter_server": parameter_server, "devices": devices,
-                          "active_devices": active_devices_per_round,
-                          "batches": number_of_batches, "batch_size": batch_size, "samples": samples,
-                          "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-            else:
-                dict_1 = {"epoch_loss_history": epoch_loss_history, "federated": federated,
-                          "parameter_server": parameter_server, "devices": devices,
-                          "batches": number_of_batches, "batch_size": batch_size, "samples": samples,
-                          "noniid": args.noniid_assignment, "data_distribution": args.random_data_distribution}
-
-            if federated:
-                sio.savemat(
-                    "results/matlab/CFA_device_{}_samples_{}_devices_{}_active_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(
-                        device_index, samples, devices, args.Ka_consensus, args.N, number_of_batches, batch_size,
-                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)
-                sio.savemat(
-                    "CFA_device_{}_samples_{}_devices_{}_neighbors_{}_batches_{}_size{}.mat".format(
-                        device_index, samples, devices, args.N, number_of_batches, batch_size), dict_1)
-            elif parameter_server:
-                sio.savemat(
-                    "results/matlab/FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(
-                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size,
-                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)
-                sio.savemat(
-                    "FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}.mat".format(
-                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size),
-                    dict_1)
-            else:  # CL
-                sio.savemat(
-                    "results/matlab/CL_samples_{}_devices_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat".format(
-                        samples, devices, number_of_batches, batch_size,
-                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)
-            break
-
-
-if __name__ == "__main__":
-
-    if args.resume == 0: # clear all files
-        # DELETE TEMPORARY CACHE FILES
-        fileList = glob.glob('results/*.npy', recursive=False)
-        print(fileList)
-        for filePath in fileList:
-            try:
-                os.remove(filePath)
-            except OSError:
-                print("Error while deleting file")
-
-        fileList = glob.glob('results/*.h5', recursive=False)
-        print(fileList)
-        for filePath in fileList:
-            try:
-                os.remove(filePath)
-            except OSError:
-                print("Error while deleting file")
-
-        fileList = glob.glob('results/*.npz', recursive=False)
-        print(fileList)
-        for filePath in fileList:
-            try:
-                os.remove(filePath)
-            except OSError:
-                print("Error while deleting file")
-
-        fileList = glob.glob('*.mat', recursive=False)
-        print(fileList)
-        for filePath in fileList:
-            try:
-                os.remove(filePath)
-            except OSError:
-                print("Error while deleting file")
-
-    # main loop for multiprocessing
-    t = []
-
-    ############# enable consensus based federation #######################
-    # federated = False
-    # federated = True
-    ########################################################
-
-    ##################### enable parameter server ##############
-    # parameter_server = False
-    server_index = devices
-    # parameter_server = True
-    #########################################################
-
-    samples = np.zeros(devices)  # training samples per device
-    for id in range(devices):
-       # samples[id]=math.floor(w[id]*validation_train)
-       # samples[id] = math.floor(balancing_vect[id]*fraction_training)
-       samples[id] = training_set_per_device
-    # samples = int(fraction_training/devices) # training samples per device
-
-    ######################### Create a non-iid assignment  ##########################
-    if args.noniid_assignment == 1:
-        total_training_size = training_set_per_device * devices
-        samples = get_noniid_data(total_training_size, devices, batch_size)
-        while np.min(samples) < batch_size:
-            samples = get_noniid_data(total_training_size, devices, batch_size)
-    #############################################################################
-    print(samples)
-
-    ####################################   code testing CL learning (0: data center)
-    # federated = False
-    # parameter_server = False
-    # processData(0, validation_train, federated, validation_train, number_of_batches, parameter_server)
-    ######################################################################################
-
-    if federated or parameter_server:
-        for ii in range(devices):
-            # position start
-            if ii == 0:
-                start_index = 0
-            else:
-                start_index = start_index + int(samples[ii-1])
-            t.append(multiprocessing.Process(target=processData, args=(ii, start_index, int(samples[ii]), federated, validation_train, number_of_batches, parameter_server, samples)))
-            t[ii].start()
-
-        # last process is for the target server
-        if parameter_server:
-            print("Target server starting with active devices {}".format(active_devices_per_round))
-            t.append(multiprocessing.Process(target=processParameterServer, args=(devices, active_devices_per_round, federated)))
-            t[devices].start()
-    else: # run centralized learning on device 0 (data center)
-        processData(0, 0, training_set_per_device*devices, federated, validation_train, number_of_batches, parameter_server, samples)
-
-    exit(0)
Index: federated_learning_keras_consensus_FL_MNIST.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from DataSets import MnistData\r\nfrom consensus.consensus_v3 import CFA_process\r\nfrom consensus.parameter_server_v2 import Parameter_Server\r\n# use only for consensus , PS only for energy efficiency\r\n# from ReplayMemory import ReplayMemory\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import models\r\nimport argparse\r\nimport warnings\r\nimport glob\r\nimport datetime\r\nimport scipy.io as sio\r\nimport multiprocessing\r\nimport math\r\nfrom matplotlib.pyplot import pause\r\nimport time\r\n\r\n\r\n\r\nwarnings.filterwarnings(\"ignore\")\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('-resume', default=0, help=\"set 1 to resume from a previous simulation, 0 to start from the beginning\", type=float)\r\nparser.add_argument('-PS', default=0, help=\"set 1 to enable PS server and FedAvg, set 0 to disable PS\", type=float)\r\nparser.add_argument('-consensus', default=1, help=\"set 1 to enable consensus, set 0 to disable\", type=float)\r\nparser.add_argument('-mu', default=0.00025, help=\"sets the learning rate for all setups\", type=float)\r\nparser.add_argument('-eps', default=1, help=\"sets the mixing parameters for model averaging (CFA)\", type=float)\r\nparser.add_argument('-target', default=0.1, help=\"sets the target loss to stop federation\", type=float)\r\nparser.add_argument('-K', default=30, help=\"sets the number of network devices\", type=int)\r\nparser.add_argument('-Ka', default=20, help=\"sets the number of active devices per round in FA (<= K)\", type=int)\r\nparser.add_argument('-N', default=1, help=\"sets the max. number of neighbors per device per round in CFA\", type=int)\r\nparser.add_argument('-Ka_consensus', default=20, help=\"sets the number of active devices for consensus\", type=int)\r\nparser.add_argument('-samp', default=500, help=\"sets the number samples per device\", type=int)\r\nparser.add_argument('-noniid_assignment', default=0, help=\" set 0 for iid assignment, 1 for non-iid random\", type=int)\r\nparser.add_argument('-run', default=0, help=\" set the run id\", type=int)\r\nparser.add_argument('-random_data_distribution', default=0, help=\" set 0 for fixed distribution, 1 for time-varying\", type=int)\r\nparser.add_argument('-batches', default=5, help=\"sets the number of batches per learning round\", type=int)\r\nparser.add_argument('-batch_size', default=100, help=\"sets the batch size per learning round\", type=int)\r\nparser.add_argument('-graph', default=6, help=\"sets the input graph: 0 for default graph, >0 uses the input graph in vGraph.mat, and choose one graph from the available adjacency matrices\", type=int)\r\nargs = parser.parse_args()\r\n\r\ndevices = args.K  # NUMBER OF DEVICES\r\nactive_devices_per_round = args.Ka\r\nmax_epochs = 200\r\n\r\n\r\nif args.consensus == 1:\r\n    federated = True\r\n    parameter_server = False\r\nelif args.PS == 1:\r\n    federated = False\r\n    parameter_server = True\r\nelse: # CL: CENTRALIZED LEARNING ON DEVICE 0 (DATA CENTER)\r\n    federated = False\r\n    parameter_server = False\r\n\r\n################# consensus, create the scheduling function ################\r\nscheduling_tx = np.zeros((devices, max_epochs*2), dtype=int)\r\nif parameter_server and not federated:\r\n    indexes_tx = np.zeros((args.Ka, max_epochs*2), dtype=int)\r\n    for k in range(max_epochs*2):\r\n        # inds = np.random.choice(devices, args.Ka, replace=False)\r\n        sr = devices - args.Ka + 1\r\n        sr2 = k % sr\r\n        inds = np.arange(sr2, args.Ka + sr2)\r\n        scheduling_tx[inds, k] = 1\r\n        indexes_tx[:,k] = inds\r\nelif not parameter_server and federated:\r\n    indexes_tx = np.zeros((args.Ka_consensus, max_epochs*2), dtype=int)\r\n    for k in range(max_epochs*2):\r\n        # inds = np.random.choice(devices, args.Ka_consensus, replace=False)\r\n        sr = devices - args.Ka_consensus + 1\r\n        sr2 = k % sr\r\n        inds = np.arange(sr2, args.Ka_consensus + sr2)\r\n        scheduling_tx[inds, k] = 1\r\n        indexes_tx[:, k] = inds\r\n###########################################################################\r\n\r\nif active_devices_per_round > devices:\r\n    active_devices_per_round = devices\r\n\r\ntarget_loss = args.target\r\n# Configuration paramaters for the whole setup\r\nseed = 42\r\n\r\n# batch_size = 5  # Size of batch taken from replay buffer\r\nbatch_size = args.batch_size\r\nnumber_of_batches = args.batches\r\ntraining_set_per_device = args.samp # NUMBER OF TRAINING SAMPLES PER DEVICE\r\nvalidation_train = 60000  # VALIDATION and training DATASET size\r\nvalidation_test = 10000\r\n\r\nif (training_set_per_device > validation_train/args.K):\r\n    training_set_per_device = math.floor(validation_train/args.K)\r\n    print(training_set_per_device)\r\n\r\nif batch_size > training_set_per_device:\r\n    batch_size = training_set_per_device\r\n\r\n# if batch_size*number_of_batches > training_set_per_device:\r\n#     number_of_batches = math.floor(training_set_per_device/batch_size)\r\n\r\n# number_of_batches = int(training_set_per_device/batch_size)\r\n# number_of_batches = args.batches\r\n\r\nnumber_of_batches_for_validation = int(validation_test/batch_size)\r\n\r\nprint(\"Number of batches for learning {}\".format(number_of_batches))\r\n\r\nmax_lag = 1 # consensus max delay 2= 2 epochs max\r\nrefresh_server = 1 # refresh server updates (in sec)\r\n\r\nn_outputs = 10  # 6 classes\r\n\r\nvalidation_start = 1 # start validation in epochs\r\n\r\n# Using huber loss for stability\r\nloss_function = keras.losses.Huber()\r\n\r\n# save scheduling format\r\n# dict_0 = {\"scheduling\": scheduling_tx, \"devices_scheduling\": indexes_tx}\r\n# sio.savemat(\"results/matlab/CFA_scheduling_devices_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}.mat\".format(devices, args.N, number_of_batches, batch_size, args.noniid_assignment, args.run), dict_0)\r\n\r\n\r\ndef get_noniid_data(total_training_size, devices, batch_size):\r\n    samples = np.random.random_integers(batch_size, total_training_size - batch_size * (devices - 1),\r\n                                        devices)  # create random numbers\r\n    samples = samples / np.sum(samples, axis=0) * total_training_size  # force them to sum to totals\r\n    # Ignore the following if you don't need integers\r\n    samples = np.round(samples)  # transform them into integers\r\n    remainings = total_training_size - np.sum(samples, axis=0)  # check if there are corrections to be done\r\n    step = 1 if remainings > 0 else -1\r\n    while remainings != 0:\r\n        i = np.random.randint(devices)\r\n        if samples[i] + step >= 0:\r\n            samples[i] += step\r\n            remainings -= step\r\n    return samples\r\n####\r\n\r\ndef preprocess_observation(obs, batch_size):\r\n    img = obs# crop and downsize\r\n    img = (img).astype(np.float)\r\n    return img.reshape(batch_size, 28, 28, 1)\r\n\r\ndef create_q_model():\r\n    # Network defined by the Deepmind paper\r\n    inputs = layers.Input(shape=(28, 28, 1,))\r\n\r\n    layer1 = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\r\n    layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)\r\n    layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(layer2)\r\n    layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)\r\n    layer5 = layers.Flatten()(layer4)\r\n\r\n    # Convolutions\r\n    # layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\r\n    # layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\r\n    # layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\r\n    #\r\n    # layer4 = layers.Flatten()(layer3)\r\n    #\r\n    # layer5 = layers.Dense(512, activation=\"relu\")(layer4)\r\n    classification = layers.Dense(n_outputs, activation=\"linear\")(layer5)\r\n\r\n    return keras.Model(inputs=inputs, outputs=classification)\r\n\r\ndef processParameterServer(devices, active_devices_per_round, federated, refresh_server=1):\r\n    model_global = create_q_model()\r\n    model_parameters_initial = np.asarray(model_global.get_weights())\r\n    parameter_server = Parameter_Server(devices, model_parameters_initial, active_devices_per_round, indexes_tx)\r\n    global_target_model = 'results/model_global.npy'\r\n    global_epoch = 'results/epoch_global.npy'\r\n    epoch_count = 0\r\n    np.save(global_target_model, model_parameters_initial)\r\n    np.save(global_epoch, epoch_count)\r\n    pause(2) # wait for neighbors\r\n    while True:\r\n        pause(refresh_server) # refresh global model on every xx seconds\r\n        fileList = glob.glob('*.mat', recursive=False)\r\n        if len(fileList) == devices:\r\n            # stop the server\r\n            break\r\n        else:\r\n            np.save(global_target_model, parameter_server.federated_target_weights_aggregation(epoch_count, aggregation_type=0))\r\n            epoch_count += 1\r\n            np.save(global_epoch, epoch_count)\r\n\r\n\r\n# execute for each deployed device\r\ndef processData(device_index, start_samples, samples, federated, full_data_size, number_of_batches, parameter_server, sample_distribution):\r\n    pause(5) # PS server (if any) starts first\r\n    checkpointpath1 = 'results/model{}.h5'.format(device_index)\r\n    outfile = 'results/dump_train_variables{}.npz'.format(device_index)\r\n    outfile_models = 'results/dump_train_model{}.npy'.format(device_index)\r\n    global_model = 'results/model_global.npy'\r\n    global_epoch = 'results/epoch_global.npy'\r\n\r\n    np.random.seed(1)\r\n    tf.random.set_seed(1)  # common initialization\r\n\r\n    learning_rate = args.mu\r\n    learning_rate_local = learning_rate\r\n\r\n    B = np.ones((devices, devices)) - tf.one_hot(np.arange(devices), devices)\r\n    Probabilities = B[device_index, :]/(devices - 1)\r\n    training_signal = False\r\n\r\n    # check for backup variables on start\r\n    if os.path.isfile(checkpointpath1):\r\n        train_start = False\r\n\r\n        # backup the model and the model target\r\n        model = models.load_model(checkpointpath1)\r\n        data_history = []\r\n        label_history = []\r\n        local_model_parameters = np.load(outfile_models, allow_pickle=True)\r\n        model.set_weights(local_model_parameters.tolist())\r\n\r\n        dump_vars = np.load(outfile, allow_pickle=True)\r\n        frame_count = dump_vars['frame_count']\r\n        epoch_loss_history = dump_vars['epoch_loss_history'].tolist()\r\n        running_loss = np.mean(epoch_loss_history[-5:])\r\n        epoch_count = dump_vars['epoch_count']\r\n    else:\r\n        train_start = True\r\n        model = create_q_model()\r\n        data_history = []\r\n        label_history = []\r\n        frame_count = 0\r\n        # Experience replay buffers\r\n        epoch_loss_history = []\r\n        epoch_count = 0\r\n        running_loss = math.inf\r\n\r\n    if parameter_server:\r\n        epoch_global = 0\r\n\r\n    training_end = False\r\n\r\n    a = model.get_weights()\r\n    # set an arbitrary optimizer, here Adam is used\r\n    optimizer = keras.optimizers.Adam(learning_rate=args.mu, clipnorm=1.0)\r\n    # create a data object (here radar data)\r\n    # start = time.time()\r\n    data_handle = MnistData(device_index, start_samples, samples, full_data_size, args.random_data_distribution)\r\n    # end = time.time()\r\n    # time_count = (end - start)\r\n    # print(Training time\"time_count)\r\n    # create a consensus object\r\n    cfa_consensus = CFA_process(devices, device_index, args.N)\r\n\r\n    while True:  # Run until solved\r\n        # collect 1 batch\r\n        frame_count += 1\r\n        obs, labels = data_handle.getTrainingData(batch_size)\r\n        data_batch = preprocess_observation(obs, batch_size)\r\n\r\n        # Save data and labels in the current learning session\r\n        data_history.append(data_batch)\r\n        label_history.append(labels)\r\n\r\n\r\n        if frame_count % number_of_batches == 0:\r\n            if not parameter_server:\r\n                epoch_count += 1\r\n            # check scheduling for federated\r\n            if federated:\r\n                if epoch_count == 1 or scheduling_tx[device_index, epoch_count] == 1:\r\n                    training_signal = False\r\n                else:\r\n                    # stop all computing, just save the previous model\r\n                    training_signal = True\r\n                    model_weights = np.asarray(model.get_weights())\r\n                    model.save(checkpointpath1, include_optimizer=True, save_format='h5')\r\n                    np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,\r\n                         training_end=training_end, epoch_count=epoch_count, loss=running_loss)\r\n                    np.save(outfile_models, model_weights)\r\n            # check scheduling for parameter server\r\n            if parameter_server:\r\n                while not os.path.isfile(global_epoch):\r\n                    # implementing consensus\r\n                    print(\"waiting\")\r\n                    pause(1)\r\n                try:\r\n                    epoch_global = np.load(global_epoch, allow_pickle=True)\r\n                except:\r\n                    pause(5)\r\n                    print(\"retrying opening global epoch counter\")\r\n                    try:\r\n                        epoch_global = np.load(global_epoch, allow_pickle=True)\r\n                    except:\r\n                        print(\"failed reading global epoch\")\r\n\r\n                if epoch_global == 0:\r\n                    training_signal = False\r\n\r\n                elif scheduling_tx[device_index, epoch_global] == 1:\r\n                    if epoch_global > epoch_count:\r\n                        epoch_count = epoch_global\r\n                        training_signal = False\r\n                    else:\r\n                        training_signal = True\r\n                else:\r\n                    # stop all computing, just save the previous model\r\n                    training_signal = True\r\n\r\n                # always refresh the local model using the PS one\r\n                stop_aggregation = False\r\n                while not os.path.isfile(global_model):\r\n                    # implementing consensus\r\n                    print(\"waiting\")\r\n                    pause(1)\r\n                try:\r\n                    model_global = np.load(global_model, allow_pickle=True)\r\n                except:\r\n                    pause(5)\r\n                    print(\"retrying opening global model\")\r\n                    try:\r\n                        model_global = np.load(global_model, allow_pickle=True)\r\n                    except:\r\n                        print(\"halting aggregation\")\r\n                        stop_aggregation = True\r\n\r\n                if not stop_aggregation:\r\n                    model.set_weights(model_global.tolist())\r\n\r\n                if training_signal:\r\n                    model_weights = np.asarray(model.get_weights())\r\n                    model.save(checkpointpath1, include_optimizer=True, save_format='h5')\r\n                    np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,\r\n                             training_end=training_end, epoch_count=epoch_count, loss=running_loss)\r\n                    np.save(outfile_models, model_weights)\r\n            # check schedulting for parameter server\r\n\r\n        # Local learning update every \"number of batches\" batches\r\n        time_count = 0\r\n        if frame_count % number_of_batches == 0 and not training_signal:\r\n            # run local batches\r\n            for i in range(number_of_batches):\r\n                start = time.time()\r\n                data_sample = np.array(data_history[i])\r\n                label_sample = np.array(label_history[i])\r\n\r\n                # Create a mask to calculate loss\r\n                masks = tf.one_hot(label_sample, n_outputs)\r\n\r\n                with tf.GradientTape() as tape:\r\n                    # Train the model on data samples\r\n                    classes = model(data_sample)\r\n                    # Apply the masks\r\n                    class_v = tf.reduce_sum(tf.multiply(classes, masks), axis=1)\r\n                    # Calculate loss\r\n                    loss = loss_function(label_sample, class_v)\r\n\r\n                # Backpropagation\r\n                grads = tape.gradient(loss, model.trainable_variables)\r\n                optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n                end = time.time()\r\n                time_count = time_count + (end-start)/number_of_batches\r\n            if not parameter_server and not federated:\r\n                print('Average batch training time {:.2f}'.format(time_count))\r\n            del data_history\r\n            del label_history\r\n            data_history = []\r\n            label_history = []\r\n\r\n            model_weights = np.asarray(model.get_weights())\r\n            model.save(checkpointpath1, include_optimizer=True, save_format='h5')\r\n            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,\r\n                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)\r\n            np.save(outfile_models, model_weights)\r\n\r\n\r\n            #  Consensus round\r\n            # update local model\r\n            cfa_consensus.update_local_model(model_weights)\r\n            # neighbor = cfa_consensus.get_connectivity(device_index, args.N, devices) # fixed neighbor\r\n\r\n            if not train_start:\r\n                if federated and not training_signal:\r\n                    eps_c = 1 / (args.N + 1)\r\n                    # apply consensus for model parameter\r\n                    # neighbor = np.random.choice(np.arange(devices), args.N, p=Probabilities, replace=False) # choose neighbor\r\n                    neighbor = np.random.choice(indexes_tx[:, epoch_count - 1], args.N, replace=False) # choose neighbor\r\n                    while neighbor == device_index:\r\n                        neighbor = np.random.choice(indexes_tx[:, epoch_count - 1], args.N,\r\n                                                    replace=False)  # choose neighbor\r\n                    print(\"Consensus from neighbor {} for device {}, local loss {:.2f}\".format(neighbor, device_index,\r\n                                                                                               loss.numpy()))\r\n\r\n                    model.set_weights(cfa_consensus.federated_weights_computing(neighbor, args.N, epoch_count, eps_c, max_lag))\r\n                    if cfa_consensus.getTrainingStatusFromNeightbor():\r\n                        # a neighbor completed the training, with loss < target, transfer learning is thus applied (the device will copy and reuse the same model)\r\n                        training_signal = True # stop local learning, just do validation\r\n            else:\r\n                print(\"Warm up\")\r\n                train_start = False\r\n\r\n            # check if parameter server is enabled\r\n            # stop_aggregation = False\r\n\r\n            # if parameter_server:\r\n            #     # pause(refresh_server)\r\n            #     while not os.path.isfile(global_model):\r\n            #         # implementing consensus\r\n            #         print(\"waiting\")\r\n            #         pause(1)\r\n            #     try:\r\n            #         model_global = np.load(global_model, allow_pickle=True)\r\n            #     except:\r\n            #         pause(5)\r\n            #         print(\"retrying opening global model\")\r\n            #         try:\r\n            #             model_global = np.load(global_model, allow_pickle=True)\r\n            #         except:\r\n            #             print(\"halting aggregation\")\r\n            #             stop_aggregation = True\r\n            #\r\n            #     if not stop_aggregation:\r\n            #         # print(\"updating from global model inside the parmeter server\")\r\n            #         for k in range(cfa_consensus.layers):\r\n            #             # model_weights[k] = model_weights[k]+ 0.5*(model_global[k]-model_weights[k])\r\n            #             model_weights[k] = model_global[k]\r\n            #         model.set_weights(model_weights.tolist())\r\n            #\r\n            #     while not os.path.isfile(global_epoch):\r\n            #         # implementing consensus\r\n            #         print(\"waiting\")\r\n            #         pause(1)\r\n            #     try:\r\n            #         epoch_global = np.load(global_epoch, allow_pickle=True)\r\n            #     except:\r\n            #         pause(5)\r\n            #         print(\"retrying opening global epoch counter\")\r\n            #         try:\r\n            #             epoch_global = np.load(global_epoch, allow_pickle=True)\r\n            #         except:\r\n            #             print(\"halting aggregation\")\r\n\r\n            del model_weights\r\n\r\n\r\n        #start = time.time()\r\n        # validation tool for device 'device_index'\r\n        if epoch_count > validation_start and frame_count % number_of_batches == 0:\r\n            avg_cost = 0.\r\n            for i in range(number_of_batches_for_validation):\r\n                obs_valid, labels_valid = data_handle.getTestData(batch_size, i)\r\n                # obs_valid, labels_valid = data_handle.getRandomTestData(batch_size)\r\n                data_valid = preprocess_observation(np.squeeze(obs_valid), batch_size)\r\n                data_sample = np.array(data_valid)\r\n                label_sample = np.array(labels_valid)\r\n                # Create a mask to calculate loss\r\n                masks = tf.one_hot(label_sample, n_outputs)\r\n                classes = model(data_sample)\r\n                # Apply the masks\r\n                class_v = tf.reduce_sum(tf.multiply(classes, masks), axis=1)\r\n                # Calculate loss\r\n                loss = loss_function(label_sample, class_v)\r\n                avg_cost += loss / number_of_batches_for_validation  # Training loss\r\n            epoch_loss_history.append(avg_cost)\r\n            print(\"Device {} epoch count {}, validation loss {:.2f}\".format(device_index, epoch_count,\r\n                                                                                 avg_cost))\r\n            # mean loss for last 5 epochs\r\n            running_loss = np.mean(epoch_loss_history[-1:])\r\n        #end = time.time()\r\n        #time_count = (end - start)\r\n        #print(time_count)\r\n\r\n        if running_loss < target_loss:  # Condition to consider the task solved\r\n            print(\"Solved for device {} at epoch {} with average loss {:.2f} !\".format(device_index, epoch_count, running_loss))\r\n            training_end = True\r\n            model_weights = np.asarray(model.get_weights())\r\n            model.save(checkpointpath1, include_optimizer=True, save_format='h5')\r\n            # model_target.save(checkpointpath2, include_optimizer=True, save_format='h5')\r\n            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,\r\n                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)\r\n            np.save(outfile_models, model_weights)\r\n\r\n            if federated:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                      \"parameter_server\": parameter_server, \"devices\": devices, \"neighbors\": args.N,\r\n                      \"active_devices\": args.Ka_consensus,\r\n                      \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples, \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n            elif parameter_server:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                          \"parameter_server\": parameter_server, \"devices\": devices,\r\n                          \"active_devices\": active_devices_per_round,\r\n                          \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples,\r\n                          \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n            else:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                          \"parameter_server\": parameter_server, \"devices\": devices,\r\n                          \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples,\r\n                          \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n\r\n            if federated:\r\n                sio.savemat(\r\n                    \"results/matlab/CFA_device_{}_samples_{}_devices_{}_active_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(\r\n                        device_index, samples, devices, args.Ka_consensus, args.N, number_of_batches, batch_size, args.noniid_assignment, args.run, args.random_data_distribution), dict_1)\r\n                sio.savemat(\r\n                    \"CFA_device_{}_samples_{}_devices_{}_neighbors_{}_batches_{}_size{}.mat\".format(\r\n                        device_index, samples, devices, args.N, number_of_batches, batch_size), dict_1)\r\n            elif parameter_server:\r\n                sio.savemat(\r\n                    \"results/matlab/FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(\r\n                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size, args.noniid_assignment,args.run, args.random_data_distribution), dict_1)\r\n                sio.savemat(\r\n                    \"FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}.mat\".format(\r\n                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size), dict_1)\r\n            else: # CL\r\n                sio.savemat(\r\n                    \"results/matlab/CL_samples_{}_devices_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(samples, devices, number_of_batches, batch_size,\r\n                                                                                                                         args.noniid_assignment, args.run, args.random_data_distribution), dict_1)\r\n            break\r\n\r\n        if epoch_count > max_epochs:  # stop simulation\r\n            print(\"Unsolved for device {} at epoch {}!\".format(device_index, epoch_count))\r\n            training_end = True\r\n            model_weights = np.asarray(model.get_weights())\r\n            model.save(checkpointpath1, include_optimizer=True, save_format='h5')\r\n            # model_target.save(checkpointpath2, include_optimizer=True, save_format='h5')\r\n            np.savez(outfile, frame_count=frame_count, epoch_loss_history=epoch_loss_history,\r\n                     training_end=training_end, epoch_count=epoch_count, loss=running_loss)\r\n            np.save(outfile_models, model_weights)\r\n\r\n            if federated:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                          \"parameter_server\": parameter_server, \"devices\": devices, \"neighbors\": args.N,\r\n                          \"active_devices\": args.Ka_consensus,\r\n                          \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples,\r\n                          \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n            elif parameter_server:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                          \"parameter_server\": parameter_server, \"devices\": devices,\r\n                          \"active_devices\": active_devices_per_round,\r\n                          \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples,\r\n                          \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n            else:\r\n                dict_1 = {\"epoch_loss_history\": epoch_loss_history, \"federated\": federated,\r\n                          \"parameter_server\": parameter_server, \"devices\": devices,\r\n                          \"batches\": number_of_batches, \"batch_size\": batch_size, \"samples\": samples,\r\n                          \"noniid\": args.noniid_assignment, \"data_distribution\": args.random_data_distribution}\r\n\r\n            if federated:\r\n                sio.savemat(\r\n                    \"results/matlab/CFA_device_{}_samples_{}_devices_{}_active_{}_neighbors_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(\r\n                        device_index, samples, devices, args.Ka_consensus, args.N, number_of_batches, batch_size,\r\n                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)\r\n                sio.savemat(\r\n                    \"CFA_device_{}_samples_{}_devices_{}_neighbors_{}_batches_{}_size{}.mat\".format(\r\n                        device_index, samples, devices, args.N, number_of_batches, batch_size), dict_1)\r\n            elif parameter_server:\r\n                sio.savemat(\r\n                    \"results/matlab/FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(\r\n                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size,\r\n                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)\r\n                sio.savemat(\r\n                    \"FA_device_{}_samples_{}_devices_{}_active_{}_batches_{}_size{}.mat\".format(\r\n                        device_index, samples, devices, active_devices_per_round, number_of_batches, batch_size),\r\n                    dict_1)\r\n            else:  # CL\r\n                sio.savemat(\r\n                    \"results/matlab/CL_samples_{}_devices_{}_batches_{}_size{}_noniid{}_run{}_distribution{}.mat\".format(\r\n                        samples, devices, number_of_batches, batch_size,\r\n                        args.noniid_assignment, args.run, args.random_data_distribution), dict_1)\r\n            break\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    if args.resume == 0: # clear all files\r\n        # DELETE TEMPORARY CACHE FILES\r\n        fileList = glob.glob('results/*.npy', recursive=False)\r\n        print(fileList)\r\n        for filePath in fileList:\r\n            try:\r\n                os.remove(filePath)\r\n            except OSError:\r\n                print(\"Error while deleting file\")\r\n\r\n        fileList = glob.glob('results/*.h5', recursive=False)\r\n        print(fileList)\r\n        for filePath in fileList:\r\n            try:\r\n                os.remove(filePath)\r\n            except OSError:\r\n                print(\"Error while deleting file\")\r\n\r\n        fileList = glob.glob('results/*.npz', recursive=False)\r\n        print(fileList)\r\n        for filePath in fileList:\r\n            try:\r\n                os.remove(filePath)\r\n            except OSError:\r\n                print(\"Error while deleting file\")\r\n\r\n        fileList = glob.glob('*.mat', recursive=False)\r\n        print(fileList)\r\n        for filePath in fileList:\r\n            try:\r\n                os.remove(filePath)\r\n            except OSError:\r\n                print(\"Error while deleting file\")\r\n\r\n    # main loop for multiprocessing\r\n    t = []\r\n\r\n    ############# enable consensus based federation #######################\r\n    # federated = False\r\n    # federated = True\r\n    ########################################################\r\n\r\n    ##################### enable parameter server ##############\r\n    # parameter_server = False\r\n    server_index = devices\r\n    # parameter_server = True\r\n    #########################################################\r\n\r\n    samples = np.zeros(devices)  # training samples per device\r\n    for id in range(devices):\r\n       # samples[id]=math.floor(w[id]*validation_train)\r\n       # samples[id] = math.floor(balancing_vect[id]*fraction_training)\r\n       samples[id] = training_set_per_device\r\n    # samples = int(fraction_training/devices) # training samples per device\r\n\r\n    ######################### Create a non-iid assignment  ##########################\r\n    if args.noniid_assignment == 1:\r\n        total_training_size = training_set_per_device * devices\r\n        samples = get_noniid_data(total_training_size, devices, batch_size)\r\n        while np.min(samples) < batch_size:\r\n            samples = get_noniid_data(total_training_size, devices, batch_size)\r\n    #############################################################################\r\n    print(samples)\r\n\r\n    ####################################   code testing CL learning (0: data center)\r\n    # federated = False\r\n    # parameter_server = False\r\n    # processData(0, validation_train, federated, validation_train, number_of_batches, parameter_server)\r\n    ######################################################################################\r\n\r\n    if federated or parameter_server:\r\n        for ii in range(devices):\r\n            # position start\r\n            if ii == 0:\r\n                start_index = 0\r\n            else:\r\n                start_index = start_index + int(samples[ii-1])\r\n            t.append(multiprocessing.Process(target=processData, args=(ii, start_index, int(samples[ii]), federated, validation_train, number_of_batches, parameter_server, samples)))\r\n            t[ii].start()\r\n\r\n        # last process is for the target server\r\n        if parameter_server:\r\n            print(\"Target server starting with active devices {}\".format(active_devices_per_round))\r\n            t.append(multiprocessing.Process(target=processParameterServer, args=(devices, active_devices_per_round, federated)))\r\n            t[devices].start()\r\n    else: # run centralized learning on device 0 (data center)\r\n        processData(0, 0, training_set_per_device*devices, federated, validation_train, number_of_batches, parameter_server, samples)\r\n\r\n    exit(0)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/federated_learning_keras_consensus_FL_MNIST.py b/federated_learning_keras_consensus_FL_MNIST.py
--- a/federated_learning_keras_consensus_FL_MNIST.py	(revision 48a4a0ba4acc8c257c486dff115b9a6b42644164)
+++ b/federated_learning_keras_consensus_FL_MNIST.py	(date 1617552253941)
@@ -25,14 +25,14 @@
 parser = argparse.ArgumentParser()
 parser.add_argument('-resume', default=0, help="set 1 to resume from a previous simulation, 0 to start from the beginning", type=float)
 parser.add_argument('-PS', default=0, help="set 1 to enable PS server and FedAvg, set 0 to disable PS", type=float)
-parser.add_argument('-consensus', default=1, help="set 1 to enable consensus, set 0 to disable", type=float)
-parser.add_argument('-mu', default=0.00025, help="sets the learning rate for all setups", type=float)
+parser.add_argument('-consensus', default=0, help="set 1 to enable consensus, set 0 to disable", type=float)
+parser.add_argument('-mu', default=0.001, help="sets the learning rate for all setups", type=float)
 parser.add_argument('-eps', default=1, help="sets the mixing parameters for model averaging (CFA)", type=float)
-parser.add_argument('-target', default=0.1, help="sets the target loss to stop federation", type=float)
-parser.add_argument('-K', default=30, help="sets the number of network devices", type=int)
+parser.add_argument('-target', default=0.05, help="sets the target loss to stop federation", type=float)
+parser.add_argument('-K', default=100, help="sets the number of network devices", type=int)
 parser.add_argument('-Ka', default=20, help="sets the number of active devices per round in FA (<= K)", type=int)
 parser.add_argument('-N', default=1, help="sets the max. number of neighbors per device per round in CFA", type=int)
-parser.add_argument('-Ka_consensus', default=20, help="sets the number of active devices for consensus", type=int)
+parser.add_argument('-Ka_consensus', default=30, help="sets the number of active devices for consensus", type=int)
 parser.add_argument('-samp', default=500, help="sets the number samples per device", type=int)
 parser.add_argument('-noniid_assignment', default=0, help=" set 0 for iid assignment, 1 for non-iid random", type=int)
 parser.add_argument('-run', default=0, help=" set the run id", type=int)
@@ -40,11 +40,13 @@
 parser.add_argument('-batches', default=5, help="sets the number of batches per learning round", type=int)
 parser.add_argument('-batch_size', default=100, help="sets the batch size per learning round", type=int)
 parser.add_argument('-graph', default=6, help="sets the input graph: 0 for default graph, >0 uses the input graph in vGraph.mat, and choose one graph from the available adjacency matrices", type=int)
+parser.add_argument('-modelselection', default=0, help="sets the model: 0 for lenet-1", type=int)
 args = parser.parse_args()
 
 devices = args.K  # NUMBER OF DEVICES
 active_devices_per_round = args.Ka
 max_epochs = 200
+condition = args.modelselection
 
 
 if args.consensus == 1:
@@ -57,6 +59,8 @@
     federated = False
     parameter_server = False
 
+
+
 ################# consensus, create the scheduling function ################
 scheduling_tx = np.zeros((devices, max_epochs*2), dtype=int)
 if parameter_server and not federated:
@@ -150,11 +154,27 @@
     # Network defined by the Deepmind paper
     inputs = layers.Input(shape=(28, 28, 1,))
 
-    layer1 = layers.Conv2D(32, kernel_size=(3, 3), activation="relu")(inputs)
-    layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)
-    layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(layer2)
-    layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)
-    layer5 = layers.Flatten()(layer4)
+    if condition == 0:
+        # lenet - 1
+     layer1 = layers.Conv2D(4, kernel_size=(5, 5), activation="relu")(inputs)
+     layer2 = layers.AveragePooling2D(pool_size=(2, 2))(layer1)
+     layer3 = layers.Conv2D(8, kernel_size=(5, 5), activation="relu")(layer2)
+     layer4 = layers.AveragePooling2D(pool_size=(2, 2))(layer3)
+     layer5 = layers.Flatten()(layer4)
+
+    elif condition == 1:
+        layer1 = layers.Conv2D(32, kernel_size=(3, 3), activation="relu")(inputs)
+        layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)
+        layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(layer2)
+        layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)
+        layer5 = layers.Flatten()(layer4)
+
+    else:
+        layer1 = layers.Conv2D(14, kernel_size=(3, 3), activation="relu")(inputs)
+        layer2 = layers.MaxPooling2D(pool_size=(2, 2))(layer1)
+        layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(layer2)
+        layer4 = layers.MaxPooling2D(pool_size=(2, 2))(layer3)
+        layer5 = layers.Flatten()(layer4)
 
     # Convolutions
     # layer1 = layers.Conv2D(32, 8, strides=4, activation="relu")(inputs)
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"ChangeListManager\">\r\n    <list default=\"true\" id=\"df19662b-489d-4b8c-9749-bd5d21758375\" name=\"Default Changelist\" comment=\"\" />\r\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\r\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\r\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\r\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\r\n  </component>\r\n  <component name=\"Git.Settings\">\r\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$/..\" />\r\n  </component>\r\n  <component name=\"ProjectId\" id=\"1qoUqUruM6G2Sj9yUiSgTI9Fi28\" />\r\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\r\n  <component name=\"ProjectViewState\">\r\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\r\n    <option name=\"showLibraryContents\" value=\"true\" />\r\n  </component>\r\n  <component name=\"PropertiesComponent\">\r\n    <property name=\"RunOnceActivity.OpenProjectViewOnStart\" value=\"true\" />\r\n    <property name=\"RunOnceActivity.ShowReadmeOnStart\" value=\"true\" />\r\n    <property name=\"last_opened_file_path\" value=\"$PROJECT_DIR$/federated_learning_keras_low_power_PS_MNIST.py\" />\r\n  </component>\r\n  <component name=\"RunManager\">\r\n    <configuration name=\"federated_learning_keras_low_power_PS_MNIST\" type=\"PythonConfigurationType\" factoryName=\"Python\" nameIsGenerated=\"true\">\r\n      <module name=\"MNIST_dataset\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"C:\\Users\\admin\\anaconda3\\envs\\mqtt\\python.exe\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/federated_learning_keras_low_power_PS_MNIST.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n  </component>\r\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\r\n  <component name=\"TaskManager\">\r\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\r\n      <changelist id=\"df19662b-489d-4b8c-9749-bd5d21758375\" name=\"Default Changelist\" comment=\"\" />\r\n      <created>1617745628149</created>\r\n      <option name=\"number\" value=\"Default\" />\r\n      <option name=\"presentableId\" value=\"Default\" />\r\n      <updated>1617745628149</updated>\r\n    </task>\r\n    <servers />\r\n  </component>\r\n  <component name=\"Vcs.Log.Tabs.Properties\">\r\n    <option name=\"TAB_STATES\">\r\n      <map>\r\n        <entry key=\"MAIN\">\r\n          <value>\r\n            <State />\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 508c617e73ac219a01963e18dbb398644239db0b)
+++ b/.idea/workspace.xml	(date 1617746740051)
@@ -1,7 +1,11 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="ChangeListManager">
-    <list default="true" id="df19662b-489d-4b8c-9749-bd5d21758375" name="Default Changelist" comment="" />
+    <list default="true" id="df19662b-489d-4b8c-9749-bd5d21758375" name="Default Changelist" comment="updated PS">
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/federated_learning_keras_consensus_FL_MNIST.py" beforeDir="false" afterPath="$PROJECT_DIR$/federated_learning_keras_consensus_FL_MNIST.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/federated_learning_keras_consensus_FL_MNIST_I.py" beforeDir="false" />
+    </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
     <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
@@ -35,7 +39,7 @@
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <option name="SCRIPT_NAME" value="$PROJECT_DIR$/federated_learning_keras_low_power_PS_MNIST.py" />
-      <option name="PARAMETERS" value="" />
+      <option name="PARAMETERS" value="-h" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
       <option name="MODULE_MODE" value="false" />
@@ -53,6 +57,21 @@
       <option name="presentableId" value="Default" />
       <updated>1617745628149</updated>
     </task>
+    <task id="LOCAL-00001" summary="updated PS">
+      <created>1617746558902</created>
+      <option name="number" value="00001" />
+      <option name="presentableId" value="LOCAL-00001" />
+      <option name="project" value="LOCAL" />
+      <updated>1617746558902</updated>
+    </task>
+    <task id="LOCAL-00002" summary="updated PS">
+      <created>1617746570487</created>
+      <option name="number" value="00002" />
+      <option name="presentableId" value="LOCAL-00002" />
+      <option name="project" value="LOCAL" />
+      <updated>1617746570487</updated>
+    </task>
+    <option name="localTasksCounter" value="3" />
     <servers />
   </component>
   <component name="Vcs.Log.Tabs.Properties">
@@ -66,4 +85,8 @@
       </map>
     </option>
   </component>
+  <component name="VcsManagerConfiguration">
+    <MESSAGE value="updated PS" />
+    <option name="LAST_COMMIT_MESSAGE" value="updated PS" />
+  </component>
 </project>
\ No newline at end of file
