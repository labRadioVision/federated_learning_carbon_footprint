Reinforcement Learning Example

Agent: crawling robot https://github.com/Freenove/Freenove_Big_Hexapod_Robot_Kit_for_Raspberry_Pi

The agent observes the environment through an RGB camera (Rasberry PI camera model V2, 8M, https://www.raspberrypi.org/products/camera-module-v2/) and a TOF sensor (TeraRanger Evo 64px - 8x8px, 5m, https://www.terabee.com/shop/3d-tof-cameras/teraranger-evo-64px/)

The action space consist of 4 robot motions: Forward (F), Backward (B), Left (L), and Right (R). Motions and cinematic are pre-programmed. Each robot explores a different site area collecting new training data (observations).

The agents (5) are preprogrammed to get positive rewards whenever they approach a target destination by following a target (pre-assigned) trajectory. To simplify the setup and the training time, the robots are forced to move on a 2D regular grid space consisting of 40 landmark points, of which 35 are usable (as no obstacles are present). The agents receive negative rewards whenever they move towards wrong positions/locations or too close to obstacles (in this case the robot is stopped depending on the TOF sensor data).



Example Dataset (folder dataset_trajectories)

Data_robots: contains the data_hexapods cell structure of size 35 x 5. Each element contains a structure with the raw images obtained from the RGB camera (camera) and TOF (terabee). Data are pre-processed and resized. Every row refers to a position index according to the defined landmark points (organized in a regular grid). Columns contain images obtained from different robots (5 robots in this example).

Lookuptab: for each position in the grid, gives the next occupied location of the robot as the result of the implementaiton of an action, namely Backward (B), Forward (F), Left (L), Right (R). Lookuptab might be generated for a custom environment using matlab_codes/getLookupTable

Reward: gives the pre-programmed rewards for each position in the grid. Rewards might be changed depening on the target trajectory or the assigned robot task.

Reinforcement Learning algorithm: Deep Q-Learning

Federated Learning method: PS (FL with Parameter Server, or vanilla Fl) and consensus-driven FL. For further details see https://arxiv.org/abs/2103.10346
